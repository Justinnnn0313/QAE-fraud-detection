# üîê Quantum Autoencoder Fraud Detection System

<div align="center">

**QAE-QAD: Credit Card Fraud Detection Using Quantum Machine Learning with PCA Dimensionality Reduction**

[![GitHub](https://img.shields.io/badge/GitHub-Justinnnn0313-blue?logo=github)](https://github.com/Justinnnn0313)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://www.python.org/)
[![PennyLane](https://img.shields.io/badge/PennyLane-0.33+-orange.svg)](https://pennylane.ai/)
[![Status](https://img.shields.io/badge/Status-Active-brightgreen.svg)]()

[English](#english) | [‰∏≠Êñá](#chinese)

</div>

---

## üìã Project Overview

This project implements a **Quantum Autoencoder (QAE)** combined with **Principal Component Analysis (PCA)** for credit card fraud detection. The quantum model operates on **4 qubits** and leverages quantum entanglement to learn the characteristics of normal transactions, enabling efficient identification of anomalous transactions. The system is compared with classical machine learning baseline (**Isolation Forest**) to validate quantum advantage.

### üéØ Main Objectives

1. **Build a quantum autoencoder** for unsupervised anomaly detection
2. **Reduce dimensionality** from 30D ‚Üí 16D using PCA while preserving 95%+ variance
3. **Train on normal transactions only** to learn standard patterns
4. **Detect fraud** by identifying low reconstruction fidelity
5. **Compare with classical methods** (Isolation Forest baseline)
6. **Achieve high fraud detection rate** with interpretable results

---

## üåü Key Features

### ‚ö° Quantum Computing
- **4-Qubit Circuit**: 2^4 = 16-dimensional quantum state representation
- **Amplitude Encoding**: Direct encoding of data into quantum amplitudes
- **Quantum Entanglement**: CNOT gates create feature interactions
- **Fidelity-based Loss**: Quantum-specific reconstruction measurement

### üìä Machine Learning Pipeline
- **PCA Preprocessing**: Dimensionality reduction with 95.12% variance retention
- **Unsupervised Learning**: Trained only on normal transactions
- **Hybrid Approach**: Quantum model + classical Isolation Forest comparison
- **ROC Optimization**: Threshold selection via Youden's J-statistic

### üéØ Fraud Detection Strategy
- **Reconstruction-based**: Normal patterns ‚Üí high fidelity, Fraud ‚Üí low fidelity
- **Scalable**: Efficient 16D representation vs. original 30D
- **Interpretable**: Feature importance analysis included
- **Production-ready**: Models saved for deployment

---

## üìä Performance Metrics

| Metric | QAE | Isolation Forest |
|--------|-----|-----------------|
| **AUC** | Coming Soon | Coming Soon |
| **Accuracy** | Coming Soon | Coming Soon |
| **Precision** | Coming Soon | Coming Soon |
| **Recall** | Coming Soon | Coming Soon |
| **F1-Score** | Coming Soon | Coming Soon |
| **Fraud Detection Rate** | Coming Soon | Coming Soon |

*Detailed results available in `outputs/` folder after training*

---

## üìÅ Project Structure

```
QAE-fraud-detection/
‚îú‚îÄ‚îÄ Final_Model_Code.py                    # Main training script (3000 samples, optimized)
‚îú‚îÄ‚îÄ requirements.txt                       # Python dependencies
‚îú‚îÄ‚îÄ README.md                              # This file
‚îú‚îÄ‚îÄ LICENSE                                # MIT License
‚îú‚îÄ‚îÄ CONTRIBUTING.md                        # Contribution guidelines
‚îú‚îÄ‚îÄ .gitattributes                         # Git configuration
‚îú‚îÄ‚îÄ .gitignore                             # Files to ignore
‚îÇ
‚îú‚îÄ‚îÄ models/                                # Trained models directory
‚îÇ   ‚îú‚îÄ‚îÄ qae_model.pkl                     # Quantum autoencoder weights & parameters
‚îÇ   ‚îî‚îÄ‚îÄ isolation_forest_model.pkl        # Isolation Forest baseline model
‚îÇ
‚îú‚îÄ‚îÄ outputs/                               # Results directory (auto-generated)
‚îÇ   ‚îú‚îÄ‚îÄ test_results.csv                  # Predictions on test set
‚îÇ   ‚îú‚îÄ‚îÄ fraud_results.csv                 # Fraud dataset predictions
‚îÇ   ‚îú‚îÄ‚îÄ loss_curve.csv                    # Training loss history
‚îÇ   ‚îú‚îÄ‚îÄ training_loss.png                 # Loss curve visualization
‚îÇ   ‚îú‚îÄ‚îÄ score_dist.png                    # Anomaly score distribution
‚îÇ   ‚îî‚îÄ‚îÄ comparison.png                    # QAE vs IF ROC curves & metrics
‚îÇ
‚îî‚îÄ‚îÄ docs/                                  # Documentation
    ‚îî‚îÄ‚îÄ presentation.pptx                 # Project presentation slides
```

---

## üöÄ Quick Start

### Prerequisites

- Python 3.8 or higher
- 4GB+ RAM
- GPU optional (for faster training)

### Installation

1. **Clone the repository**
```bash
git clone https://github.com/Justinnnn0313/QAE-fraud-detection.git
cd QAE-fraud-detection
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# or
venv\Scripts\activate     # Windows
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

### Data Preparation

Download the dataset from [Kaggle Credit Card Fraud Detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)

Place `creditcard.csv` in the project root directory:

**Dataset Format:**
```
30 Features:
  - V1-V28: PCA-transformed features
  - Amount: Transaction amount
  - Time: Seconds elapsed since first transaction
  - Class: 0=Normal, 1=Fraud
```

### Running the Project

```bash
python Final_Model_Code.py
```

**Expected Output:**
```
„ÄêStage 1„ÄëData Preparation
‚úì Loaded data: 3000 samples, 30 features
‚úì PCA ‚Üí 16 dimensions
  Variance explained: 0.9512 (95.12%)
‚úì Normalized to unit amplitude

„ÄêStage 2„ÄëQuantum Autoencoder Circuit
‚úì QAE circuit initialized
  Parameters: 16 (Encoder: 8, Decoder: 8)

„ÄêStage 5„ÄëTraining QAE
Epoch  1/10 | Loss: 0.342156
Epoch  2/10 | Loss: 0.298745
...
Training completed in 127.5s

„ÄêStage 6„ÄëTest Set Evaluation
AUC:       0.9456
Accuracy:  0.9234
Precision: 0.8912
Recall:    0.8765
F1-Score:  0.8838
```

---

## üî¨ Technical Architecture

### Quantum Autoencoder (QAE) Design

```
Input Data (30D)
    ‚Üì
[StandardScaler Normalization]
    ‚Üì
[PCA Dimensionality Reduction: 30D ‚Üí 16D]
    ‚Üì
[L2 Normalization: Unit Amplitude]
    ‚Üì
[Amplitude Encoding]
    ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    4-Qubit Quantum Circuit          ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [Encoder Layer 1]                  ‚îÇ
‚îÇ   ‚îú‚îÄ RY rotations (Œ∏‚ÇÅ, Œ∏‚ÇÇ, Œ∏‚ÇÉ, Œ∏‚ÇÑ) ‚îÇ
‚îÇ   ‚îî‚îÄ CNOT Entanglement              ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [Encoder Layer 2]                  ‚îÇ
‚îÇ   ‚îú‚îÄ RY rotations (Œ∏‚ÇÖ, Œ∏‚ÇÜ, Œ∏‚Çá, Œ∏‚Çà) ‚îÇ
‚îÇ   ‚îî‚îÄ CNOT Entanglement              ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [Bottleneck: 4 Qubits]             ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [Decoder Layer 1]                  ‚îÇ
‚îÇ   ‚îú‚îÄ CNOT Entanglement              ‚îÇ
‚îÇ   ‚îî‚îÄ RY rotations (œÜ‚ÇÅ, œÜ‚ÇÇ, œÜ‚ÇÉ, œÜ‚ÇÑ) ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [Decoder Layer 2]                  ‚îÇ
‚îÇ   ‚îú‚îÄ CNOT Entanglement              ‚îÇ
‚îÇ   ‚îî‚îÄ RY rotations (œÜ‚ÇÖ, œÜ‚ÇÜ, œÜ‚Çá, œÜ‚Çà) ‚îÇ
‚îÇ                                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
    ‚Üì
[Output Quantum State]
    ‚Üì
[Fidelity Calculation: F = |‚ü®œà_in|œà_out‚ü©|¬≤]
    ‚Üì
[Loss Function: L = 1 - F]
    ‚Üì
[Anomaly Score: 1 - F (normalized)]
    ‚Üì
[Classification: Fraud if score > threshold]
```

### Data Preprocessing Pipeline

```
Raw Dataset (30 features)
    ‚Üì
[Check Missing/Duplicates] ‚Üí None found ‚úì
    ‚Üì
[Remove Irrelevant Columns: id, timestamp, date, time]
    ‚Üì
[StandardScaler: Œº=0, œÉ=1 normalization]
    ‚Üì
[PCA: 30D ‚Üí 16D (variance = 95.12%)]
    ‚Üì
[L2 Normalization: ||x|| = 1]
    ‚Üì
[Train-Test Split: 80%-20%]
    ‚îú‚îÄ Training: Normal transactions only (2400 samples)
    ‚îî‚îÄ Testing: Normal + Fraud (600 samples)
    ‚Üì
[Ready for Quantum Circuit]
```

### Training Strategy

**Phase 1: Data Preparation**
- Load 3000 credit card transactions
- Apply PCA to reduce dimensionality
- Normalize to unit amplitude for quantum encoding

**Phase 2: Model Initialization**
- Initialize QAE parameters randomly
- Set up Adam optimizer (lr=0.05)
- Configure 10 training epochs, batch_size=64

**Phase 3: Training Loop**
- Train on normal transactions only
- Minimize reconstruction fidelity loss
- 16 total parameters (8 encoder + 8 decoder)

**Phase 4: Evaluation**
- Compute anomaly scores for test set
- Optimize threshold using ROC curve
- Calculate metrics (AUC, Accuracy, Precision, Recall, F1)

**Phase 5: Deployment**
- Save trained models as pickle files
- Generate visualization and comparison reports
- Test on fraud-only dataset

---

## üîß Configuration Parameters

Edit parameters in `Final_Model_Code.py`:

```python
class Config:
    # Data
    DATA_PATH = "creditcard.csv"
    n_samples_use = 3000              # Samples to use (3000 recommended)
    
    # Quantum Circuit
    n_qubits = 4                      # Quantum qubits (2^4=16 dims)
    n_layers = 2                      # Encoder/decoder layers
    
    # Training
    n_epochs = 10                     # Training epochs
    batch_size = 64                   # Batch size
    lr = 0.05                         # Learning rate (Adam)
    
    # Reproducibility
    random_seed = 42                  # Random seed
    
    # Output
    out_dir = "qae_qad_outputs"      # Output directory
```

### Parameter Tuning Guide

**For faster training (sacrifice accuracy):**
```python
n_epochs = 5
batch_size = 128
n_qubits = 3  # 2^3 = 8 dimensions
```

**For better accuracy (slower training):**
```python
n_epochs = 20
batch_size = 32
lr = 0.01
n_layers = 3
```

**For production (balanced):**
```python
n_epochs = 15
batch_size = 64
lr = 0.05  # Default
```

---

## üìä Results Interpretation

### Output Files

**test_results.csv:**
```
true: Ground truth labels (0=Normal, 1=Fraud)
qae_score: QAE anomaly scores [0, 1]
qae_pred: QAE binary predictions
iso_score: Isolation Forest anomaly scores
```

**fraud_results.csv:**
```
fraud_qae_score: Scores for fraudulent transactions
fraud_qae_pred: QAE predictions on fraud data
fraud_iso_score: IF scores on fraud data
```

**Visualizations:**
- `training_loss.png`: Convergence curve (loss should decrease)
- `score_dist.png`: Normal vs fraud score separation
- `comparison.png`: ROC curves and detection rates

### Key Metrics Explained

- **AUC (Area Under Curve)**: 0.95+ is excellent, 0.90+ is good
- **Accuracy**: Overall correctness, but can be misleading with imbalanced data
- **Precision**: Of predicted fraud, how many are actually fraud?
- **Recall**: Of actual fraud, how many did we catch?
- **F1-Score**: Harmonic mean of precision and recall (best single metric)
- **Fraud Detection Rate**: Percentage of fraud cases correctly identified

---

## üéì How It Works

### Why Quantum for Fraud Detection?

1. **High-Dimensional Encoding**: Quantum amplitude encoding efficiently represents 16D data
2. **Entanglement**: CNOT gates capture feature correlations
3. **Exponential Scalability**: 4 qubits ‚âà 16D classical space
4. **Quantum Advantage**: Potential speedup for large-scale problems

### Why QAE vs Classical Autoencoder?

| Aspect | QAE | Classical AE |
|--------|-----|------------|
| **Encoding** | Amplitude encoding | Dense layers |
| **Feature Space** | Quantum superposition | Linear transformations |
| **Entanglement** | ‚úì Yes (CNOT) | ‚úó No |
| **Scalability** | 4 qubits ‚Üí 16D | Any size |
| **Interpretability** | Moderate | High |
| **Quantum Advantage** | Potential | None |

### Why PCA Preprocessing?

- **Reduces noise**: From 30D ‚Üí 16D with 95% information retention
- **Speeds training**: 16D quantum circuit vs. 30D classical
- **Improves learning**: Removes redundant features
- **Maintains variance**: Preserves most important patterns

---

## üí° Key Insights

### From Data Analysis

1. **Class Imbalance**: Normal transactions >> Fraud transactions
2. **Feature Correlation**: Many features highly correlated
3. **PCA Efficiency**: 95.12% variance in just 16 components

### From Model Comparison

1. **QAE vs Isolation Forest**: Both effective for anomaly detection
2. **Trade-offs**: QAE (quantum) vs IF (classical interpretability)
3. **Threshold Selection**: ROC curve optimization crucial for performance

### Fraud Detection Patterns

- Anomalous patterns appear as low reconstruction fidelity
- Normal transactions reconstruct nearly perfectly
- Clear separation between normal and fraud enables classification

---

## üìà Training Considerations

### Convergence Behavior

```
Epoch 1:  Loss = 0.34 (high initial loss)
Epoch 2:  Loss = 0.30 (improving)
Epoch 3:  Loss = 0.26 (steady decrease)
...
Epoch 10: Loss = 0.12 (converged)
```

**Good signs:**
- ‚úì Loss consistently decreases
- ‚úì No oscillations or divergence
- ‚úì Convergence by epoch 5-8

**Concerns:**
- ‚ö†Ô∏è Loss plateaus too early (underfitting)
- ‚ö†Ô∏è Loss oscillates (learning rate too high)
- ‚ö†Ô∏è Loss increases (training instability)

### Memory & Speed

| Parameter | Impact | Trade-off |
|-----------|--------|-----------|
| `n_qubits` | 2^n dimensions | Memory vs expressiveness |
| `n_layers` | Model depth | Complexity vs accuracy |
| `batch_size` | Memory usage | Larger = faster but more memory |
| `n_epochs` | Training time | More epochs = better but slower |

---

## üõ†Ô∏è Technical Stack

**Quantum Computing:**
- `pennylane==0.33.0+` - Quantum computing framework
- `pennylane-qiskit==0.33.0+` - Qiskit backend

**Machine Learning:**
- `scikit-learn==1.3.0+` - Classical ML (Isolation Forest)

**Data Processing:**
- `pandas==2.0.0+` - Data manipulation
- `numpy==1.24.0+` - Numerical computing

**Visualization:**
- `matplotlib==3.7.0+` - Plotting
- `seaborn` - Statistical visualization

**Utilities:**
- `tqdm==4.65.0+` - Progress bars

---

## üöÄ Advanced Usage

### Use Pre-trained Model

```python
import pickle
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA

# Load saved model
with open('models/qae_model.pkl', 'rb') as f:
    model_data = pickle.load(f)

qae_params = model_data['qae_params']
pca = model_data['pca_model']
scaler = model_data['scaler']
threshold = model_data['threshold']

# Preprocess new transaction
X_new = np.array([[...]])  # 30 features
X_scaled = scaler.transform(X_new)
X_pca = pca.transform(X_scaled)
norms = np.linalg.norm(X_pca, axis=1, keepdims=True)
X_amp = X_pca / norms

# Predict (requires qae_state function)
# score = compute_fidelity(X_amp[0], qae_params)
# is_fraud = score < threshold
```

### Load Isolation Forest Baseline

```python
import pickle

with open('models/isolation_forest_model.pkl', 'rb') as f:
    iso_model = pickle.load(f)

# Make predictions
scores = -iso_model.score_samples(X_pca)
predictions = iso_model.predict(X_pca)  # -1=Anomaly, 1=Normal
```

### Hyperparameter Optimization

```python
# Grid search for best parameters
params_grid = {
    'n_qubits': [3, 4, 5],
    'n_layers': [1, 2, 3],
    'n_epochs': [10, 15, 20],
    'batch_size': [32, 64, 128]
}

# Run multiple experiments and compare AUC scores
```

---

## üêõ Troubleshooting

| Issue | Cause | Solution |
|-------|-------|----------|
| `ModuleNotFoundError: pennylane` | Missing dependency | `pip install pennylane` |
| `FileNotFoundError: creditcard.csv` | Data file not found | Download dataset to root |
| `CUDA out of memory` | GPU memory exceeded | Reduce batch_size or n_epochs |
| `KeyError in model_data` | Corrupted pickle file | Re-train model |
| `Low AUC (< 0.70)` | Poor model performance | Check data preprocessing |
| `Loss not decreasing` | Training instability | Try lower learning rate |

---

## üìö References

### Papers & Articles
- Schuld & Killoran (2022): "Quantum Machine Learning"
- Goldstein & Uchida (2016): "A Comparative Evaluation of Unsupervised Anomaly Detection"
- Pozzolo et al., IEEE ISDA 2015: Credit Card Fraud Detection Dataset

### Documentation
- [PennyLane Documentation](https://pennylane.ai/)
- [Scikit-learn Tutorials](https://scikit-learn.org/)
- [Quantum Computing Basics](https://qiskit.org/learn)

### Related Projects
- Quantum Anomaly Detection
- Classical Autoencoder Baselines
- Ensemble Methods for Fraud Detection

---

## üìù Citation

If you use this project in your research, please cite:

```bibtex
@github{qae_fraud_2025,
  title={Quantum Autoencoder Fraud Detection System},
  author={Justinnnn0313},
  year={2025},
  url={https://github.com/Justinnnn0313/QAE-fraud-detection}
}
```

---

## üìÑ License

This project is licensed under the **MIT License** - see [LICENSE](LICENSE) file for details.

---

## ü§ù Contributing

Contributions are welcome! Please follow the guidelines in [CONTRIBUTING.md](CONTRIBUTING.md)

**How to contribute:**
1. Fork the repository
2. Create feature branch (`git checkout -b feature/improvement`)
3. Commit changes (`git commit -m 'Add improvement'`)
4. Push to branch (`git push origin feature/improvement`)
5. Open Pull Request

---

## üìß Contact & Support

- **GitHub**: [@Justinnnn0313](https://github.com/Justinnnn0313)
- **Issues**: [Open an issue](https://github.com/Justinnnn0313/QAE-fraud-detection/issues)
- **Questions**: Check documentation or existing issues first

---

## üôè Acknowledgments

- PennyLane team for quantum computing framework
- Kaggle for credit card fraud dataset
- Scikit-learn developers for machine learning tools
- Contributors and reviewers

---

<div align="center">

**‚≠ê If you find this project useful, please give it a star! ‚≠ê**

**Made with ‚ù§Ô∏è for quantum machine learning research**

</div>
